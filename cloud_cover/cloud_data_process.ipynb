{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68735414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#讀取檔案位置與輸出檔案位置\n",
    "original_path='D:/solar_eng/中興/elsie_hw/cloud_cover_original/'\n",
    "processed_path='D:/solar_eng/中興/elsie_hw/cloud_cover_processed/'\n",
    "#讀取資料夾中所有檔案名稱並存成list，且另存一個輸出檔案名稱list\n",
    "all_original_name= os.listdir(original_path)\n",
    "all_processed_name= [ os.path.splitext(i)[0]+'_processed.csv' for i in all_original_name ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39f2ea27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸出檔案：\n",
      "cloud.fst.v35_solar_南鹽光_034_processed.csv\n",
      "cloud.fst.v35_solar_崙尾光_033_processed.csv\n",
      "cloud.fst.v35_solar_彰濱光_032_processed.csv\n",
      "cloud.fst.v38_solar_南鹽光_034_processed.csv\n",
      "cloud.fst.v38_solar_崙尾光_033_processed.csv\n",
      "cloud.fst.v38_solar_彰濱光_032_processed.csv\n"
     ]
    }
   ],
   "source": [
    "#設定目標檔名的關鍵字\n",
    "cloudFile_name_key='cloud.fst'\n",
    "\n",
    "print(\"輸出檔案：\")\n",
    "#使用for迴圈到all_original_name的list中抓取目前檔案名稱\n",
    "for i in range(len(all_original_name)):\n",
    "    #若非目標檔案則跳過不處理\n",
    "    if cloudFile_name_key not in all_original_name[i]:\n",
    "        continue\n",
    "        \n",
    "    # 讀取資料(檔名來源：all_original_name)\n",
    "    df = pd.read_csv(original_path+all_original_name[i])\n",
    "    #讀取經緯度\n",
    "    lon=df['lon'][1]\n",
    "    lat=df['lat'][1]\n",
    "\n",
    "    \n",
    "    # 將date_time欄位轉換成datetime格式\n",
    "    df['fst_time'] = pd.to_datetime(df['fst_time'])\n",
    "\n",
    "\n",
    "    #將重複資料刪除，只保留最後一筆資料\n",
    "    duplicate_mask = df.duplicated(subset='fst_time', keep='last')\n",
    "    df = df[~duplicate_mask]\n",
    "\n",
    "    # 做填充\n",
    "    df['mid'].fillna(df['hig'], inplace=True)\n",
    "    df['low'].fillna(df['mid'], inplace=True)\n",
    "\n",
    "\n",
    "    # 將fst_time欄位設定為索引\n",
    "    df.set_index('fst_time', inplace=True)\n",
    "\n",
    "    # 進行重取樣，將十分鐘一筆資料重取樣為5分鐘一筆\n",
    "    df = df.resample('5T').first().reset_index()\n",
    "\n",
    "    df['lon'].fillna(lon, inplace=True)\n",
    "    df['lat'].fillna(lat, inplace=True)\n",
    "\n",
    "    df[['low','mid','hig','cloud']] = df[['low','mid','hig','cloud']].interpolate()\n",
    "\n",
    "    # 將dfst_time轉換為datetime格式\n",
    "    df['fst_time'] = pd.to_datetime(df['fst_time'])\n",
    "\n",
    "    # 選擇時間等於15、30、45或00分的資料\n",
    "    df = df[df['fst_time'].dt.minute.isin([15, 30, 45, 0])]\n",
    "\n",
    "    # 刪除date_time欄位\n",
    "    df.drop('date_time', axis=1, inplace=True)\n",
    "\n",
    "    # 將\"fst_time\"列名更改為\"date_time\"\n",
    "    df = df.rename(columns={'fst_time': 'date_time'})\n",
    "\n",
    "    # 輸出df2(檔名來源：all_processed_name)\n",
    "    df.to_csv(processed_path+all_processed_name[i], index=None)\n",
    "    print(all_processed_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b78af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸出檔案：\n",
      "CF_南鹽光_034_processed.csv\n",
      "CF_崙尾光_033_processed.csv\n",
      "CF_彰濱光_032_processed.csv\n"
     ]
    }
   ],
   "source": [
    "#創建儲存power值的字典\n",
    "power_dict={'南鹽光':150,'崙尾光':181,'彰濱光':100}\n",
    "#設定目標檔名的關鍵字\n",
    "powerFile_name_key='CF_'\n",
    "\n",
    "print(\"輸出檔案：\")\n",
    "#使用for迴圈到all_original_name的list中抓取目前檔案名稱\n",
    "for i in range(len(all_original_name)):\n",
    "    #若非目標檔案則跳過不處理\n",
    "    if powerFile_name_key not in all_original_name[i]:\n",
    "        continue\n",
    "        \n",
    "    #重置power值\n",
    "    power=None\n",
    "    #讀取目標檔案\n",
    "    df = pd.read_csv(original_path+all_original_name[i])\n",
    "\n",
    "#若需要將capacity_factor乘上裝置容量，則將以下幾行取消註解\n",
    "#     #讀取此檔案的power值，存為變數power\n",
    "#     for key, value in power_dict.items():\n",
    "#         if str(key) in all_original_name[i]:\n",
    "#             #power為預存valu\n",
    "#             power=value\n",
    "#             break;\n",
    "#     #確認是否有存到power值\n",
    "#     if power is None:\n",
    "#         print(all_original_name[i]+\"缺少power值，停止轉換\")\n",
    "#         break;\n",
    "\n",
    "    #讀取此檔案的經緯度\n",
    "    lon=df['lon'][1]\n",
    "    lat=df['lat'][1]\n",
    "    \n",
    "\n",
    "    #將格式轉為datetime並且加上10min，使其從50分成為整點資料\n",
    "    df['time'] = pd.to_datetime(df['time'])+ pd.Timedelta(minutes=10)\n",
    "    #將時間設為index\n",
    "    df.set_index('time', inplace=True)\n",
    "    #將時間間距調整為15min\n",
    "    df = df.resample('15T').first().reset_index()\n",
    "    #使用線性插值補上空值\n",
    "#若需要將capacity_factor乘上裝置容量，將乘上power值取消註解\n",
    "    df['capacity_factor']=df['capacity_factor'].interpolate()#*power\n",
    "    #將經緯度的空值填滿\n",
    "    df['lon'].fillna(lon, inplace=True)\n",
    "    df['lat'].fillna(lat, inplace=True)\n",
    "\n",
    "    \n",
    "    # 輸出df2(檔名來源：all_processed_name)\n",
    "    df.to_csv(processed_path+all_processed_name[i], index=None)\n",
    "    print(all_processed_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911407e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#讀取檔案位置與輸出檔案位置\n",
    "#power+cloud的資料夾位置\n",
    "mergeSource_path='D:/solar_eng/中興/elsie_hw/cloud_cover_processed/'\n",
    "#匯出檔案的位置+檔名\n",
    "mergeTarget_path='D:/solar_eng/中興/elsie_hw/solar_汙水廠_newbig_sort(history_15m).csv'\n",
    "mergedOutput_path='D:/solar_eng/中興/elsie_hw/merged_processed/'\n",
    "\n",
    "cloudFile_name_key_v35='cloud.fst.v35'\n",
    "cloudFile_name_key_v38='cloud.fst.v38'\n",
    "powerFile_name_key='CF_'\n",
    "powerSource_name=[]\n",
    "cloudSource_name_v35=[]\n",
    "cloudSource_name_v38=[]\n",
    "#讀取資料夾中所有檔案名稱，並將檔名分類存成power的list，和cloud的list\n",
    "for i in os.listdir(mergeSource_path):\n",
    "    if powerFile_name_key in i:\n",
    "        powerSource_name.append(i)\n",
    "    elif cloudFile_name_key_v35 in i:\n",
    "        cloudSource_name_v35.append(i)\n",
    "    elif cloudFile_name_key_v38 in i:\n",
    "        cloudSource_name_v38.append(i)\n",
    "    else:\n",
    "        print('未處理檔案：'+i)\n",
    "        \n",
    "#讀取匯入用表格\n",
    "df_target=pd.read_csv(mergeTarget_path)\n",
    "#將時間欄位轉為相同格式\n",
    "df_target['TIME_TO_INTERVAL']=pd.to_datetime(df_target['TIME_TO_INTERVAL'])\n",
    "df_target['TIME_TO_INTERVAL'] = df_target['TIME_TO_INTERVAL'].astype(str)\n",
    "\n",
    "\n",
    "for i in range(len(powerSource_name)):\n",
    "    df_powerSource = pd.read_csv(mergeSource_path+powerSource_name[i])\n",
    "    df_cloudSource_v35=pd.read_csv(mergeSource_path+cloudSource_name_v35[i])\n",
    "    df_cloudSource_v38=pd.read_csv(mergeSource_path+cloudSource_name_v38[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 合併Power資料\n",
    "    df_merged_power = pd.merge(df_target, df_powerSource, left_on='TIME_TO_INTERVAL',right_on='time', how='inner')\n",
    "    # 填充空值\n",
    "    df_merged_power['Power']=df_merged_power['capacity_factor']\n",
    "    # 將重複欄位刪除\n",
    "    df_merged_power.drop(columns=['capacity_factor','lon','lat','time'], inplace=True)\n",
    "\n",
    "    #合併雲資料，輸出兩份檔案(v35、v38各一)\n",
    "    df_merged_v35 = pd.merge(df_merged_power, df_cloudSource_v35, left_on='TIME_TO_INTERVAL',right_on='date_time', how='inner')\n",
    "    df_merged_v38 = pd.merge(df_merged_power, df_cloudSource_v38, left_on='TIME_TO_INTERVAL',right_on='date_time', how='inner')\n",
    "    #將v35、v38中各自的空值刪除\n",
    "    df_merged_v35.drop(columns=['date_time'], inplace=True)\n",
    "    df_merged_v38.drop(columns=['date_time'], inplace=True)\n",
    "\n",
    "    sdf=df_merged_v35.iloc[29900:300101]\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    sdf.head(100)\n",
    "    #輸出df_merged_v35和df_merged_v38\n",
    "    df_merged_v35.to_csv(mergedOutput_path+cloudSource_name_v35[i].replace('processed','merged'), index=None)\n",
    "    df_merged_v38.to_csv(mergedOutput_path+cloudSource_name_v38[i].replace('processed','merged'), index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e9546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
